{
 "metadata": {
  "name": "",
  "signature": "sha256:cc32bc2c2c362d0438bbe8c0b32078a470961660e6e7f38fd15536cb78e7e2e8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Mondrian Forests\n",
      "\n",
      "This is a reimplementation of Mondrian Forests as described here:\n",
      "\n",
      "**Mondrian Forests: Efficient Online Random Forests**\n",
      "\n",
      "Balaji Lakshminarayanan, Daniel M. Roy, Yee Whye Teh\n",
      "\n",
      "http://arxiv.org/abs/1406.2673\n",
      "\n",
      "It partly uses code from the original authors' implementation at\n",
      "\n",
      "https://github.com/balajiln/mondrianforest\n",
      "\n",
      "but changes a few things along the way too. Key differences:\n",
      "\n",
      "* Assume FAST_MODE (no log-likelihood) for now\n",
      "* Classification only (they never finished regression)\n",
      "* Always assume we're training incrementally\n",
      "* `data` (an array) refers to one batch, instead of having a single design matrix in memory and indexing it with `train_ids`\n",
      "* `labels` is a vector of class labels for the rows in `data`\n",
      "* We don't assume you'll provide the first batch of training data when initializing a tree, but we do need to know the number of dimensions and number of labels\n",
      "* It works in parallel :-)\n",
      "\n",
      "Perhaps most different of all:\n",
      "\n",
      "We don't keep all the input data, as this won't scale; we just keep class label frequencies (plus bounding box extents). But this means we can't move existing class frequencies down into new leaf nodes when the tree grows, as we don't know which child they would end up in. (Because we only have the label frequencies of the items that are in that node, not their coordinates...)\n",
      "\n",
      "So, when new data makes the tree grow new nodes, we keep all the *existing* class frequencies where they are, and only use the new children for *newly-arriving* data -- so internal nodes (and the root) can retain frequencies from when they were leaf nodes. Then we take these into account when calculating the predictive posteriors (modifying the algorithm presented in appendix A of paper). This is working, but could do with slightly better testing, and a more theoretical analysis of how/why it works.\n",
      "\n",
      "Here are my original thoughts on this, that I almost sent to the authors, but decided to try first.\n",
      "\n",
      "```\n",
      "One thing I missed on reading the paper, is that when you bisect a leaf node through a \"grow\" (sampling) operation,\n",
      "you need to assign all its data points to one of the new children.\n",
      "\n",
      "This means you can't just keep summary statistics for the data in a block, i.e. class frequencies. You need to hold\n",
      "on to the raw training data in order to divide it, yes? Which is a problem for online learning over streaming data\n",
      "or just \"big data\" in general.\n",
      "\n",
      "So... Perhaps you could entirely forget about keeping the existing data and propagating it down to the new child\n",
      "nodes. If you just kept class frequencies at each node, maybe you could use these in the \"update posterior counts\"\n",
      "step for internal nodes, alongside the child node counts.\n",
      "\n",
      "(Any data that came in *after* the split would go all the way down to the leaf nodes though.)\n",
      "```\n",
      "\n",
      "It also includes a much simpler scoring system, which again relies on the data-retaining property of internal nodes. Walk down the tree until you find the box that the test example would have been in, and return its class probabilities. If you don't find a box, or it's empty, walk back up until you find the nearest ancestor with some instances in, and use those probabilities instead. This actually does pretty well.\n",
      "\n",
      "## Understanding the budget parameter and split costs\n",
      "\n",
      "The tree's budget is a positive float value that controls how deep and complex it can get, by limiting the total number of splits it's allowed to make.\n",
      "\n",
      "You could just let each tree grow forever, and giving it budget == `np.inf` will allow that, but this will eat up memory and prohibit large-scale streaming deployments, as each tree's memory usage is O(n_nodes * n_dimensions).\n",
      "\n",
      "Doing this would also make the tree's performance degrade over time. Adding a node is \"linear in the depth of the tree\", and depth in turn is \"typically logarithmic in n\" [the training data size] according to the paper. Making a prediction is probably also O(log n) as it's a very similar process to adding new data.\n",
      "\n",
      "The budget parameter lets you put an upper limit on these costs. This is how it works...\n",
      "\n",
      "Every node as a `budget` variable, and a `max_split_cost` variable which controls how big a split it can currently accommodate. For the root node, you provide `budget` at tree creation time, and `max_split_cost` is initially set to 0.\n",
      "\n",
      "Newly-arriving data 'flows' down the tree from the root, following the existing splits at each node. Sometimes, it will flow through an internal node whose associated bounding box doesn't cover the extents of the new data, at which point the node must either grow its box to encompass the new data, or split, replacing itself with a new parent and adding a sibling to hold the any new data that it doesn't cover.\n",
      "\n",
      "A 'split cost' is generated by drawing from an exponential distribution, parameterized by the amount the node's bounding box would have to grow in order to cover the new data if it didn't split. Therefore the more far-flung the data is, the *less* the split costs -- because if the node is almost big enough to hold the data, we prefer to just grow it rather than making the tree more complex.\n",
      "\n",
      "The split cost is compared to the node's `max_split_cost`, and if it's smaller, the node splits.\n",
      "\n",
      "## Running this demo\n",
      "\n",
      "If a `default` IPython cluster is available, it runs in parallel automatically, with as many trees in the forest as you have engines in the cluster. Otherwise, it runs in serial on a single core, with 3 trees. See the notes in the third cell.\n",
      "\n",
      "For best results with small forests, use an odd number of trees. (That's what I anecdotally observed anyway, but this may be more like superstition than science.)\n",
      "\n",
      "## TODO\n",
      "\n",
      "### Must-haves\n",
      "\n",
      "* Types for all numpy arrays (partly done)\n",
      "* More complete error checking\n",
      "* Work out exactly what effect `budget` is having\n",
      "* Introspection and prettyprinting tools\n",
      "* Work out which members are \"private\" and rename them with underscores\n",
      "* Proper tests...\n",
      "\n",
      "### Useful features\n",
      "\n",
      "* Allow multiple trees per engine (i.e. each engine runs a forest, not a tree)\n",
      "* Instance subsampling\n",
      "* Feature subsampling/bootstrapping/bagging\n",
      "* Feature hashing/random projection/LSH\n",
      "* Train-on-fail mode\n",
      "* Loss functions, regret, class weighting?\n",
      "\n",
      "### Blue sky\n",
      "\n",
      "* Regression\n",
      "* Clustering? (I mean, it basically *is* clustering, already...)\n",
      "* Semi-supervised would be really easy too\n",
      "* Adaptivity -- non-stationary distributions, recency effects etc.\n",
      "* Auto-pruning/rebalancing -- stop trees either stagnating or growing out of control in the long term\n",
      "* What about when the true number of classes isn't known in advance?\n",
      "\n",
      "The last three are really closely related.\n",
      "\n",
      "We could probably tackle a lot of these problems by \"chopping down\" older trees -- either randomly or according to a heuristic (e.g. least-recently-modified) -- so new ones can grow in their place. Maybe varying the budget and discount values would be useful too.\n",
      "\n",
      "Perhaps you could calculate the posterior class probabilities over the entire 'dead' tree, and use these as the priors for the new tree that will grow in its place.\n",
      "\n",
      "You could also use this kind of approach to tune P/R tradeoff, chase a particular objective function, do reinforcement learning... If you squint, they start to look a little like GAs.\n",
      "\n",
      "* Ontology learning\n",
      "* Grammar induction\n",
      "* Topic modelling\n",
      "\n",
      "Use cases that are fundamentally tree-shaped! Hmmm."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%run 'mondrian.py'\n",
      "\n",
      "import random\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import pprint\n",
      "\n",
      "from IPython.parallel import Client\n",
      "try:\n",
      "    rc = Client()\n",
      "    dview = rc[:]\n",
      "    print('Using default IPython cluster with %d engines' % len(dview))\n",
      "except FileNotFoundError:\n",
      "    rc = None\n",
      "    dview = None\n",
      "    print('Using single-core implementation')\n",
      "\n",
      "DEFAULT_BUDGET = 0.001"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "import gzip\n",
      "import os\n",
      "import pandas as pd\n",
      "from sklearn import datasets\n",
      "from sklearn import cross_validation as cv\n",
      "\n",
      "# For speed later...\n",
      "test_file = '/home/vagrant/data/covtype.pkl.gz'\n",
      "if os.path.exists(test_file):\n",
      "    with gzip.GzipFile(test_file, 'rb') as z:\n",
      "        dataset = pickle.load(z)\n",
      "else:\n",
      "    dataset = datasets.fetch_covtype() # Can be quite slow\n",
      "    with gzip.GzipFile(test_file, 'wb') as z:\n",
      "        pickle.dump(dataset, z)\n",
      "        \n",
      "dataset.data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_iter = 500\n",
      "train_size = 1000\n",
      "test_size = 10\n",
      "folds = cv.StratifiedShuffleSplit(dataset.target, n_iter=n_iter, test_size=test_size, train_size=train_size)\n",
      "hits = []\n",
      "\n",
      "data = dataset.data\n",
      "target = dataset.target - 1 # they are 1-indexed\n",
      "data_size = data.shape[1]\n",
      "classes = len(np.unique(target))\n",
      "\n",
      "local_trees = 11\n",
      "remote_trees_per_worker = 11\n",
      "scoring = 'nsp'\n",
      "\n",
      "def run_test(mf):\n",
      "    for i, (train, test) in enumerate(folds):\n",
      "        train_X = data[train]\n",
      "        train_y = target[train]\n",
      "        test_X = data[test]\n",
      "        test_y = target[test]\n",
      "        mf.update(train_X, train_y)\n",
      "        preds = mf.predict(test_X)\n",
      "        yhat = preds.argmax(axis=1)\n",
      "        assert test_y.shape == yhat.shape\n",
      "        for j in range(len(preds)):\n",
      "            idx = (i * test_size) + j\n",
      "            print(idx, '- Predicted:', yhat[j], 'Actual:', test_y[j],\n",
      "                  '[', ' '.join(['%.3f' % x for x in preds[j]]), ']')\n",
      "            hits.append(yhat[j] == test_y[j])\n",
      "    return mf\n",
      "\n",
      "if dview is None:\n",
      "    # Run with a single-threaded forest\n",
      "    mf = MondrianForest(local_trees, data_size, classes, DEFAULT_BUDGET, scoring)\n",
      "    %prun status = run_test(mf).status()\n",
      "    pprint.pprint(status)\n",
      "else:\n",
      "    # Run with a parallel forest on IPython cluster\n",
      "    pmf = ParallelMondrianForest(dview, remote_trees_per_worker, data_size, classes, DEFAULT_BUDGET, scoring)\n",
      "    status = run_test(pmf).status()\n",
      "    pprint.pprint(status)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print('Overall accuracy:', sum(hits)/len(hits))\n",
      "print('Cumulative correct predictions over training epoch:')\n",
      "p = pd.Series(hits).cumsum().plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}