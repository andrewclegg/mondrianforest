{
 "metadata": {
  "name": "",
  "signature": "sha256:428bd8e2da578caed00311d1e43a1e708ef991dcd0f5c786edd2d80646f705a3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Mondrian Forests\n",
      "\n",
      "Key differences from original:\n",
      "\n",
      "* Assume FAST_MODE (no log-likelihood) for now\n",
      "* Classification only (they never finished regression)\n",
      "* Always assume we're training incrementally\n",
      "* `update_posterior_node_incremental` just becomes `update_label_counts`\n",
      "* `add_training_points_to_node` just becomes `MondrianNode.update`\n",
      "* Pushed as much metadata as possible into the node object, to avoid having lots of separate dicts etc. maintained by the tree (hence renaming it `MondrianNode`)\n",
      "* `data` (an array) refers to one batch, instead of having a single design matrix in memory and indexing it with `train_ids`\n",
      "* `labels` is a vector of class labels for the rows in `data`\n",
      "* We don't assume you'll provide the first batch of training data when initializing a tree, but we do need to know the number of dimensions and number of labels\n",
      "* It works in parallel :-)\n",
      "\n",
      "Perhaps most different of all:\n",
      "\n",
      "We don't keep all the input data, as this won't scale. But this means we can't move existing data down into the new leaf nodes when we split a leaf node.\n",
      "\n",
      "This is the plan: When the tree \"grows\" through randomly splitting a leaf node, keep its existing class frequencies where they are, and only use the two new children for *newly-arriving* data. Then take these into account when calculating the predictive posteriors (appendix A of paper).\n",
      "\n",
      "Here's my thoughts, that I almost sent to Balaji, but decided to try first.\n",
      "\n",
      "```\n",
      "One thing I missed on reading the paper, is that when you bisect a leaf node through a \"grow\" (sampling) operation,\n",
      "you need to assign all its data points to one of the new children.\n",
      "\n",
      "This means you can't just keep summary statistics for the data in a block, i.e. class frequencies. You need to hold\n",
      "on to the raw training data in order to divide it, yes? Which is a problem for online learning over streaming data\n",
      "or just \"big data\" in general.\n",
      "\n",
      "So... Perhaps you could entirely forget about keeping the existing data and propagating it down to the new child\n",
      "nodes. If you just kept class frequencies at each node, maybe you could use these in the \"update posterior counts\"\n",
      "step for internal nodes, alongside the child node counts.\n",
      "\n",
      "(Any data that came in *after* the split would go all the way down to the leaf nodes though.)\n",
      "```\n",
      "\n",
      "For the time being, though, it's using a much simpler scoring system. Walk down the tree until you find the box that the test example would have been in, and go for the majority class. If you don't find a box, or it's empty, walk back up until you find the nearest parent with some instances in.\n",
      "\n",
      "Averaged across a few trees, even as few as ~10, this actually does pretty well.\n",
      "\n",
      "### TODO\n",
      "\n",
      "* Proper probabilistic scoring\n",
      "* Work out exactly what effect `budget` is having\n",
      "* Introspection and prettyprinting tools\n",
      "* Instance subsampling\n",
      "* Feature subsampling/bootstrapping/bagging\n",
      "* Feature hashing/random projection/LSH\n",
      "* Perf. tuning (Cython etc.)\n",
      "* Error checking\n",
      "* Bulk prediction\n",
      "* Train-on-fail mode\n",
      "* Loss functions, regret, class weighting?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%run 'mondrian.py'\n",
      "\n",
      "import random\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "from IPython.parallel import Client\n",
      "rc = Client()\n",
      "dview = rc[:10]\n",
      "\n",
      "DEFAULT_BUDGET = 1000"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 179
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "import gzip\n",
      "import os\n",
      "import pandas as pd\n",
      "from sklearn import datasets\n",
      "from sklearn import cross_validation as cv\n",
      "\n",
      "# For speed later...\n",
      "test_file = '/home/vagrant/data/covtype.pkl.gz'\n",
      "if os.path.exists(test_file):\n",
      "    with gzip.GzipFile(test_file, 'rb') as z:\n",
      "        dataset = pickle.load(z)\n",
      "else:\n",
      "    dataset = datasets.fetch_covtype() # Can be quite slow\n",
      "    with gzip.GzipFile(test_file, 'wb') as z:\n",
      "        pickle.dump(dataset, z)\n",
      "        \n",
      "dataset.data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 136,
       "text": [
        "(581012, 54)"
       ]
      }
     ],
     "prompt_number": 136
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%prun\n",
      "\n",
      "n_iter = 30\n",
      "folds = cv.StratifiedShuffleSplit(dataset.target, n_iter=n_iter, test_size=10, train_size=1000)\n",
      "hits = np.ndarray(n_iter, dtype=bool)\n",
      "\n",
      "data = dataset.data\n",
      "target = dataset.target - 1 # they are 1-indexed\n",
      "\n",
      "mf = MondrianForest(3, data.shape[1], len(np.unique(target)), budget=DEFAULT_BUDGET)\n",
      "\n",
      "def run_test():\n",
      "    for i, (train, test) in enumerate(folds):\n",
      "        train_X = data[train]\n",
      "        train_y = target[train]\n",
      "        # TODO use the rest of the test subset, not just the first one, each time\n",
      "        test_X = data[test][0:1,:]\n",
      "        test_y = target[test][0:1]\n",
      "        mf.update(train_X, train_y)\n",
      "        preds = mf.predict(test_X, True)\n",
      "        yhat = preds.argmax()\n",
      "        print(i, '- Predicted:', yhat, 'Actual:', test_y,\n",
      "              '[', ' '.join(['%.3f' % x for x in preds]), ']')\n",
      "        hits[i] = yhat == test_y\n",
      "\n",
      "run_test()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0 - Predicted: 1 Actual: [0] [ 0.365 0.488 0.062 0.005 0.016 0.030 0.035 ]\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: [0] [ 0.331 0.460 0.106 0.009 0.018 0.052 0.024 ]\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: [0] [ 0.383 0.489 0.050 0.003 0.024 0.024 0.027 ]\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: [1] [ 0.227 0.582 0.082 0.010 0.024 0.064 0.012 ]\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: [1] [ 0.284 0.476 0.140 0.010 0.027 0.055 0.008 ]\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: [1] [ 0.451 0.471 0.012 0.000 0.014 0.008 0.045 ]\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: [1] [ 0.390 0.523 0.020 0.001 0.013 0.014 0.040 ]\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: [1] [ 0.287 0.704 0.002 0.000 0.001 0.001 0.004 ]\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: [1] [ 0.141 0.583 0.148 0.009 0.013 0.093 0.014 ]\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: [0] [ 0.476 0.483 0.017 0.001 0.006 0.006 0.010 ]\n",
        "10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: [0] [ 0.441 0.509 0.008 0.000 0.008 0.005 0.029 ]\n",
        "11"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 0 Actual: [0] [ 0.568 0.320 0.007 0.000 0.005 0.007 0.093 ]\n",
        "12"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 2 Actual: [2] [ 0.009 0.228 0.609 0.018 0.009 0.127 0.000 ]\n",
        "13"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: [1] [ 0.281 0.634 0.058 0.000 0.018 0.009 0.000 ]\n",
        "14"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: [1] [ 0.323 0.614 0.040 0.000 0.011 0.006 0.006 ]\n",
        "15"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: [1] [ 0.192 0.781 0.000 0.000 0.000 0.000 0.028 ]\n",
        "16"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 0 Actual: [1] [ 0.468 0.421 0.000 0.000 0.000 0.000 0.111 ]\n",
        "17"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 0 Actual: [0] [ 0.552 0.429 0.000 0.000 0.000 0.000 0.019 ]\n",
        "18"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: [1] [ 0.130 0.855 0.000 0.000 0.015 0.000 0.000 ]\n",
        "19"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: [1] [ 0.322 0.628 0.002 0.000 0.002 0.046 0.000 ]\n",
        "20"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 0 Actual: [0] [ 0.500 0.500 0.000 0.000 0.000 0.000 0.000 ]\n",
        "21"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: [1] [ 0.141 0.816 0.037 0.000 0.005 0.000 0.000 ]\n",
        "22"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: [1] [ 0.269 0.670 0.022 0.000 0.000 0.011 0.027 ]\n",
        "23"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 0 Actual: [1] [ 0.511 0.489 0.000 0.000 0.000 0.000 0.000 ]\n",
        "24"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: [1] [ 0.329 0.662 0.004 0.000 0.000 0.000 0.005 ]\n",
        "25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 0 Actual: [0] [ 0.523 0.458 0.006 0.000 0.006 0.003 0.005 ]\n",
        "26"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 0 Actual: [0] [ 0.514 0.478 0.000 0.000 0.000 0.000 0.009 ]\n",
        "27"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 0 Actual: [0] [ 0.768 0.152 0.000 0.000 0.000 0.000 0.080 ]\n",
        "28"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: [1] [ 0.197 0.773 0.000 0.000 0.030 0.000 0.000 ]\n",
        "29"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: [1] [ 0.135 0.865 0.000 0.000 0.000 0.000 0.000 ]\n",
        " "
       ]
      }
     ],
     "prompt_number": 180
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.Series(hits.cumsum()).plot() # Predictions over time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 109,
       "text": [
        "<matplotlib.axes._subplots.AxesSubplot at 0x7f53298c5c18>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEACAYAAABF+UbAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nx1TERURy7P8AgNKtMd/YU54AAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f53298c54e0>"
       ]
      }
     ],
     "prompt_number": 109
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hits.sum()/len(hits) # Overall accuracy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "0.746"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.amin??"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    }
   ],
   "metadata": {}
  }
 ]
}