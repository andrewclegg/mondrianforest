{
 "metadata": {
  "name": "",
  "signature": "sha256:de556536994031e63f4f727b72e49f9293916ba3ba6484cfb8296ff7a85f8879"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Mondrian Forests\n",
      "\n",
      "This is a reimplementation of Mondrian Forests as described here:\n",
      "\n",
      "**Mondrian Forests: Efficient Online Random Forests**\n",
      "\n",
      "Balaji Lakshminarayanan, Daniel M. Roy, Yee Whye Teh\n",
      "\n",
      "http://arxiv.org/abs/1406.2673\n",
      "\n",
      "It partly uses code from the original authors' implementation at\n",
      "\n",
      "https://github.com/balajiln/mondrianforest\n",
      "\n",
      "but changes a few things along the way too. Key differences:\n",
      "\n",
      "* Assume FAST_MODE (no log-likelihood) for now\n",
      "* Classification only (they never finished regression)\n",
      "* Always assume we're training incrementally\n",
      "* `data` (an array) refers to one batch, instead of having a single design matrix in memory and indexing it with `train_ids`\n",
      "* `labels` is a vector of class labels for the rows in `data`\n",
      "* We don't assume you'll provide the first batch of training data when initializing a tree, but we do need to know the number of dimensions and number of labels\n",
      "* It works in parallel :-)\n",
      "\n",
      "Perhaps most different of all:\n",
      "\n",
      "We don't keep all the input data, as this won't scale. But this means we can't move existing data down into the new leaf nodes when we split a leaf node.\n",
      "\n",
      "This is the plan: When the tree \"grows\" through randomly splitting a leaf node, keep its existing class frequencies where they are, and only use the two new children for *newly-arriving* data. Then take these into account when calculating the predictive posteriors (appendix A of paper). This is working, but not very well tested yet.\n",
      "\n",
      "Here are my original thoughts on this, that I almost sent to the authors, but decided to try first.\n",
      "\n",
      "```\n",
      "One thing I missed on reading the paper, is that when you bisect a leaf node through a \"grow\" (sampling) operation,\n",
      "you need to assign all its data points to one of the new children.\n",
      "\n",
      "This means you can't just keep summary statistics for the data in a block, i.e. class frequencies. You need to hold\n",
      "on to the raw training data in order to divide it, yes? Which is a problem for online learning over streaming data\n",
      "or just \"big data\" in general.\n",
      "\n",
      "So... Perhaps you could entirely forget about keeping the existing data and propagating it down to the new child\n",
      "nodes. If you just kept class frequencies at each node, maybe you could use these in the \"update posterior counts\"\n",
      "step for internal nodes, alongside the child node counts.\n",
      "\n",
      "(Any data that came in *after* the split would go all the way down to the leaf nodes though.)\n",
      "```\n",
      "\n",
      "For the time being, though, it's using a much simpler scoring system. Walk down the tree until you find the box that the test example would have been in, and go for the majority class. If you don't find a box, or it's empty, walk back up until you find the nearest ancestor with some instances in.\n",
      "\n",
      "Averaged across a few trees, even as few as ~10, this actually does pretty well.\n",
      "\n",
      "## Running this demo\n",
      "\n",
      "If a `default` IPython cluster is available, it runs in parallel automatically, with as many trees in the forest as you have engines in the cluster. Otherwise, it runs in serial on a single core, with 3 trees. See the notes in the third cell.\n",
      "\n",
      "For best results with small forests, use an odd number of trees.\n",
      "\n",
      "## TODO\n",
      "\n",
      "### Must-haves\n",
      "\n",
      "* Types for all numpy arrays\n",
      "* Error checking\n",
      "* Work out exactly what effect `budget` is having\n",
      "* Introspection and prettyprinting tools\n",
      "* Work out which members are \"private\" and rename them with underscores\n",
      "* Proper tests...\n",
      "\n",
      "### Useful features\n",
      "\n",
      "* Allow multiple trees per engine (i.e. each engine runs a forest, not a tree)\n",
      "* Instance subsampling\n",
      "* Feature subsampling/bootstrapping/bagging\n",
      "* Feature hashing/random projection/LSH\n",
      "* Train-on-fail mode\n",
      "* Loss functions, regret, class weighting?\n",
      "\n",
      "### Blue sky\n",
      "\n",
      "* Regression\n",
      "* Clustering? (I mean, it basically *is* clustering, already...)\n",
      "* Semi-supervised would be really easy too\n",
      "* Adaptivity -- non-stationary distributions, recency effects etc.\n",
      "* Auto-pruning/rebalancing -- stop trees either stagnating or growing out of control in the long term\n",
      "* What about when the true number of classes isn't known in advance?\n",
      "\n",
      "The last three are really closely related.\n",
      "\n",
      "We could probably tackle a lot of these problems by \"chopping down\" older trees -- either randomly or according to a heuristic (e.g. least-recently-modified) -- so new ones can grow in their place. Maybe varying the budget and discount values would be useful too.\n",
      "\n",
      "Perhaps you could calculate the posterior class probabilities over the entire 'dead' tree, and use these as the priors for the new tree that will grow in its place.\n",
      "\n",
      "You could also use this kind of approach to tune P/R tradeoff, chase a particular objective function, do reinforcement learning... If you squint, they start to look a little like GAs.\n",
      "\n",
      "* Ontology learning\n",
      "* Grammar induction\n",
      "* Topic modelling\n",
      "\n",
      "Use cases that are fundamentally tree-shaped! Hmmm."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%run 'mondrian.py'\n",
      "\n",
      "import random\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "from IPython.parallel import Client\n",
      "try:\n",
      "    rc = Client()\n",
      "    dview = rc[:]\n",
      "    print('Using default IPython cluster with %d engines' % len(dview))\n",
      "except FileNotFoundError:\n",
      "    rc = None\n",
      "    dview = None\n",
      "    print('Using single-core implementation')\n",
      "\n",
      "DEFAULT_BUDGET = 1000"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using default IPython cluster with 11 engines\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "import gzip\n",
      "import os\n",
      "import pandas as pd\n",
      "from sklearn import datasets\n",
      "from sklearn import cross_validation as cv\n",
      "\n",
      "# For speed later...\n",
      "test_file = '/home/vagrant/data/covtype.pkl.gz'\n",
      "if os.path.exists(test_file):\n",
      "    with gzip.GzipFile(test_file, 'rb') as z:\n",
      "        dataset = pickle.load(z)\n",
      "else:\n",
      "    dataset = datasets.fetch_covtype() # Can be quite slow\n",
      "    with gzip.GzipFile(test_file, 'wb') as z:\n",
      "        pickle.dump(dataset, z)\n",
      "        \n",
      "dataset.data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "(581012, 54)"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_iter = 50\n",
      "test_size = 10\n",
      "folds = cv.StratifiedShuffleSplit(dataset.target, n_iter=n_iter, test_size=test_size, train_size=1000)\n",
      "hits = []\n",
      "\n",
      "data = dataset.data\n",
      "target = dataset.target - 1 # they are 1-indexed\n",
      "data_size = data.shape[1]\n",
      "classes = len(np.unique(target))\n",
      "\n",
      "local_trees = 11\n",
      "remote_trees_per_worker = 11\n",
      "scoring = 'nsp'\n",
      "\n",
      "def run_test():\n",
      "    for i, (train, test) in enumerate(folds):\n",
      "        train_X = data[train]\n",
      "        train_y = target[train]\n",
      "        test_X = data[test]\n",
      "        test_y = target[test]\n",
      "        mf.update(train_X, train_y)\n",
      "        preds = mf.predict(test_X)\n",
      "        yhat = preds.argmax(axis=1)\n",
      "        assert test_y.shape == yhat.shape\n",
      "        for j in range(len(preds)):\n",
      "            idx = (i * test_size) + j\n",
      "            print(idx, '- Predicted:', yhat[j], 'Actual:', test_y[j],\n",
      "                  '[', ' '.join(['%.3f' % x for x in preds[j]]), ']')\n",
      "            hits.append(yhat[j] == test_y[j])\n",
      "\n",
      "if dview is None:\n",
      "    # Run with a single-threaded forest\n",
      "    mf = MondrianForest(local_trees, data_size, classes, DEFAULT_BUDGET, scoring)\n",
      "    %prun run_test()\n",
      "else:\n",
      "    # Run with a parallel forest on IPython cluster\n",
      "    mf = ParallelMondrianForest(dview, remote_trees_per_worker, data_size, classes, DEFAULT_BUDGET, scoring)\n",
      "    run_test()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0 - Predicted: 1 Actual: 1 [ 0.223 0.474 0.127 0.010 0.033 0.061 0.072 ]\n",
        "1 - Predicted: 1 Actual: 1 [ 0.223 0.474 0.127 0.010 0.033 0.061 0.072 ]\n",
        "2 - Predicted: 1 Actual: 1 [ 0.223 0.474 0.127 0.010 0.033 0.061 0.072 ]\n",
        "3 - Predicted: 1 Actual: 1 [ 0.223 0.474 0.127 0.010 0.033 0.061 0.072 ]\n",
        "4 - Predicted: 1 Actual: 0 [ 0.223 0.474 0.127 0.010 0.033 0.061 0.072 ]\n",
        "5 - Predicted: 1 Actual: 2 [ 0.223 0.474 0.127 0.010 0.033 0.061 0.072 ]\n",
        "6 - Predicted: 1 Actual: 0 [ 0.223 0.474 0.127 0.010 0.033 0.061 0.072 ]\n",
        "7 - Predicted: 1 Actual: 1 [ 0.223 0.474 0.127 0.010 0.033 0.061 0.072 ]\n",
        "8 - Predicted: 1 Actual: 0 [ 0.223 0.474 0.127 0.010 0.033 0.061 0.072 ]\n",
        "9 - Predicted: 1 Actual: 0 [ 0.223 0.474 0.127 0.010 0.033 0.061 0.072 ]\n",
        "10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: 2 [ 0.249 0.410 0.160 0.011 0.032 0.075 0.063 ]\n",
        "11 - Predicted: 1 Actual: 1 [ 0.282 0.454 0.110 0.007 0.027 0.052 0.068 ]\n",
        "12 - Predicted: 1 Actual: 0 [ 0.272 0.414 0.136 0.009 0.032 0.064 0.072 ]\n",
        "13 - Predicted: 1 Actual: 0 [ 0.287 0.448 0.104 0.007 0.028 0.050 0.077 ]\n",
        "14 - Predicted: 1 Actual: 0 [ 0.254 0.416 0.152 0.010 0.033 0.072 0.063 ]\n",
        "15 - Predicted: 1 Actual: 1 [ 0.296 0.462 0.096 0.006 0.026 0.047 0.067 ]\n",
        "16 - Predicted: 1 Actual: 1 [ 0.308 0.488 0.078 0.005 0.022 0.037 0.062 ]\n",
        "17 - Predicted: 1 Actual: 1 [ 0.315 0.471 0.080 0.005 0.023 0.039 0.067 ]\n",
        "18 - Predicted: 1 Actual: 0 [ 0.312 0.527 0.058 0.004 0.018 0.028 0.054 ]\n",
        "19 - Predicted: 1 Actual: 1 [ 0.286 0.466 0.099 0.006 0.026 0.048 0.069 ]\n",
        "20"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: 1 [ 0.351 0.388 0.108 0.006 0.030 0.052 0.065 ]\n",
        "21 - Predicted: 1 Actual: 1 [ 0.344 0.367 0.123 0.007 0.031 0.060 0.068 ]\n",
        "22 - Predicted: 1 Actual: 2 [ 0.318 0.376 0.144 0.009 0.033 0.070 0.051 ]\n",
        "23 - Predicted: 0 Actual: 0 [ 0.375 0.358 0.110 0.006 0.027 0.052 0.072 ]\n",
        "24 - Predicted: 1 Actual: 0 [ 0.359 0.379 0.105 0.006 0.028 0.051 0.073 ]\n",
        "25 - Predicted: 1 Actual: 1 [ 0.384 0.450 0.057 0.003 0.015 0.027 0.063 ]\n",
        "26 - Predicted: 1 Actual: 0 [ 0.354 0.409 0.090 0.005 0.024 0.045 0.073 ]\n",
        "27 - Predicted: 1 Actual: 0 [ 0.352 0.358 0.122 0.007 0.032 0.060 0.068 ]\n",
        "28 - Predicted: 1 Actual: 1 [ 0.310 0.378 0.148 0.009 0.034 0.069 0.053 ]\n",
        "29 - Predicted: 1 Actual: 1 [ 0.351 0.368 0.121 0.007 0.032 0.059 0.062 ]\n",
        "30"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: 0 [ 0.369 0.528 0.031 0.004 0.013 0.020 0.035 ]\n",
        "31 - Predicted: 1 Actual: 1 [ 0.356 0.391 0.114 0.007 0.028 0.054 0.050 ]\n",
        "32 - Predicted: 1 Actual: 0 [ 0.408 0.437 0.042 0.003 0.017 0.025 0.070 ]\n",
        "33 - Predicted: 1 Actual: 2 [ 0.369 0.377 0.103 0.007 0.028 0.056 0.060 ]\n",
        "34 - Predicted: 0 Actual: 1 [ 0.445 0.430 0.043 0.002 0.010 0.023 0.047 ]\n",
        "35 - Predicted: 0 Actual: 0 [ 0.404 0.371 0.080 0.005 0.024 0.044 0.072 ]\n",
        "36 - Predicted: 1 Actual: 1 [ 0.327 0.397 0.136 0.007 0.025 0.059 0.049 ]\n",
        "37 - Predicted: 1 Actual: 1 [ 0.357 0.388 0.117 0.008 0.032 0.052 0.046 ]\n",
        "38 - Predicted: 1 Actual: 1 [ 0.319 0.391 0.147 0.008 0.026 0.064 0.046 ]\n",
        "39 - Predicted: 1 Actual: 0 [ 0.401 0.463 0.037 0.002 0.014 0.021 0.062 ]\n",
        "40"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: 0 [ 0.374 0.397 0.097 0.007 0.022 0.049 0.055 ]\n",
        "41 - Predicted: 1 Actual: 1 [ 0.441 0.474 0.025 0.001 0.008 0.013 0.038 ]\n",
        "42 - Predicted: 0 Actual: 0 [ 0.457 0.422 0.030 0.002 0.012 0.018 0.059 ]\n",
        "43 - Predicted: 1 Actual: 1 [ 0.407 0.421 0.057 0.003 0.018 0.031 0.063 ]\n",
        "44 - Predicted: 1 Actual: 2 [ 0.291 0.359 0.193 0.016 0.020 0.089 0.033 ]\n",
        "45 - Predicted: 1 Actual: 1 [ 0.283 0.403 0.169 0.007 0.033 0.075 0.030 ]\n",
        "46 - Predicted: 1 Actual: 1 [ 0.367 0.412 0.095 0.006 0.021 0.047 0.053 ]\n",
        "47 - Predicted: 0 Actual: 0 [ 0.452 0.401 0.041 0.002 0.015 0.024 0.065 ]\n",
        "48 - Predicted: 0 Actual: 0 [ 0.410 0.384 0.075 0.004 0.021 0.041 0.065 ]\n",
        "49 - Predicted: 1 Actual: 1 [ 0.301 0.611 0.020 0.005 0.012 0.013 0.038 ]\n",
        "50"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: 1 [ 0.370 0.539 0.035 0.002 0.015 0.014 0.026 ]\n",
        "51 - Predicted: 0 Actual: 0 [ 0.506 0.441 0.016 0.001 0.006 0.010 0.020 ]\n",
        "52 - Predicted: 1 Actual: 1 [ 0.461 0.466 0.025 0.001 0.008 0.016 0.023 ]\n",
        "53 - Predicted: 1 Actual: 1 [ 0.401 0.443 0.064 0.003 0.017 0.030 0.042 ]\n",
        "54 - Predicted: 1 Actual: 0 [ 0.421 0.527 0.014 0.001 0.005 0.009 0.024 ]\n",
        "55 - Predicted: 1 Actual: 0 [ 0.416 0.439 0.054 0.003 0.017 0.030 0.041 ]\n",
        "56 - Predicted: 1 Actual: 2 [ 0.195 0.337 0.324 0.021 0.036 0.072 0.015 ]\n",
        "57 - Predicted: 1 Actual: 0 [ 0.387 0.395 0.091 0.005 0.022 0.046 0.054 ]\n",
        "58 - Predicted: 1 Actual: 1 [ 0.385 0.538 0.016 0.001 0.008 0.012 0.041 ]\n",
        "59 - Predicted: 1 Actual: 1 [ 0.358 0.436 0.081 0.004 0.024 0.044 0.053 ]\n",
        "60"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: 1 [ 0.379 0.419 0.107 0.004 0.020 0.031 0.041 ]\n",
        "61 - Predicted: 1 Actual: 0 [ 0.379 0.493 0.044 0.004 0.020 0.031 0.028 ]\n",
        "62 - Predicted: 0 Actual: 0 [ 0.485 0.402 0.023 0.002 0.011 0.012 0.066 ]\n",
        "63 - Predicted: 1 Actual: 1 [ 0.410 0.474 0.032 0.002 0.015 0.016 0.051 ]\n",
        "64 - Predicted: 1 Actual: 1 [ 0.389 0.439 0.077 0.005 0.017 0.038 0.035 ]\n",
        "65 - Predicted: 1 Actual: 1 [ 0.378 0.467 0.064 0.004 0.017 0.032 0.038 ]\n",
        "66 - Predicted: 1 Actual: 0 [ 0.368 0.438 0.087 0.004 0.020 0.041 0.041 ]\n",
        "67 - Predicted: 1 Actual: 2 [ 0.249 0.448 0.155 0.011 0.028 0.094 0.015 ]\n",
        "68 - Predicted: 0 Actual: 0 [ 0.443 0.414 0.045 0.003 0.015 0.022 0.058 ]\n",
        "69 - Predicted: 1 Actual: 1 [ 0.268 0.462 0.139 0.006 0.033 0.079 0.013 ]\n",
        "70"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 0 Actual: 0 [ 0.459 0.445 0.024 0.002 0.013 0.014 0.043 ]\n",
        "71 - Predicted: 1 Actual: 1 [ 0.310 0.637 0.007 0.000 0.005 0.004 0.038 ]\n",
        "72 - Predicted: 1 Actual: 0 [ 0.296 0.461 0.145 0.006 0.017 0.061 0.015 ]\n",
        "73 - Predicted: 1 Actual: 0 [ 0.379 0.442 0.101 0.003 0.013 0.037 0.025 ]\n",
        "74 - Predicted: 1 Actual: 0 [ 0.407 0.484 0.032 0.001 0.018 0.019 0.040 ]\n",
        "75 - Predicted: 1 Actual: 1 [ 0.347 0.572 0.020 0.002 0.015 0.011 0.032 ]\n",
        "76 - Predicted: 0 Actual: 1 [ 0.482 0.414 0.026 0.001 0.011 0.013 0.053 ]\n",
        "77 - Predicted: 1 Actual: 2 [ 0.318 0.479 0.092 0.004 0.023 0.059 0.025 ]\n",
        "78 - Predicted: 0 Actual: 1 [ 0.440 0.434 0.040 0.003 0.020 0.024 0.039 ]\n",
        "79 - Predicted: 1 Actual: 1 [ 0.406 0.479 0.037 0.001 0.017 0.027 0.034 ]\n",
        "80"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: 1 [ 0.382 0.579 0.011 0.001 0.007 0.007 0.013 ]\n",
        "81 - Predicted: 1 Actual: 1 [ 0.240 0.717 0.011 0.001 0.007 0.006 0.018 ]\n",
        "82 - Predicted: 1 Actual: 0 [ 0.323 0.532 0.077 0.003 0.016 0.032 0.018 ]\n",
        "83 - Predicted: 1 Actual: 2 [ 0.163 0.394 0.270 0.029 0.013 0.118 0.013 ]\n",
        "84 - Predicted: 0 Actual: 0 [ 0.457 0.441 0.027 0.002 0.015 0.016 0.042 ]\n",
        "85 - Predicted: 1 Actual: 1 [ 0.391 0.524 0.022 0.001 0.014 0.013 0.035 ]\n",
        "86 - Predicted: 1 Actual: 1 [ 0.277 0.487 0.144 0.009 0.011 0.053 0.019 ]\n",
        "87 - Predicted: 0 Actual: 0 [ 0.447 0.439 0.031 0.002 0.014 0.015 0.053 ]\n",
        "88 - Predicted: 1 Actual: 0 [ 0.339 0.520 0.065 0.004 0.019 0.029 0.024 ]\n",
        "89 - Predicted: 1 Actual: 1 [ 0.297 0.489 0.122 0.006 0.010 0.055 0.020 ]\n",
        "90"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: 0 [ 0.373 0.488 0.050 0.003 0.015 0.037 0.033 ]\n",
        "91 - Predicted: 0 Actual: 0 [ 0.465 0.463 0.023 0.002 0.009 0.012 0.026 ]\n",
        "92 - Predicted: 1 Actual: 1 [ 0.319 0.564 0.060 0.003 0.015 0.027 0.011 ]\n",
        "93 - Predicted: 1 Actual: 1 [ 0.375 0.467 0.066 0.002 0.022 0.047 0.022 ]\n",
        "94 - Predicted: 1 Actual: 1 [ 0.384 0.530 0.031 0.002 0.013 0.019 0.020 ]\n",
        "95 - Predicted: 1 Actual: 0 [ 0.410 0.503 0.030 0.001 0.010 0.009 0.037 ]\n",
        "96 - Predicted: 2 Actual: 2 [ 0.122 0.321 0.340 0.026 0.024 0.161 0.005 ]\n",
        "97 - Predicted: 1 Actual: 1 [ 0.249 0.515 0.122 0.011 0.016 0.069 0.017 ]\n",
        "98 - Predicted: 0 Actual: 1 [ 0.591 0.375 0.008 0.000 0.004 0.006 0.015 ]\n",
        "99 - Predicted: 0 Actual: 0 [ 0.573 0.385 0.012 0.000 0.004 0.005 0.021 ]\n",
        "100"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: 1 [ 0.453 0.522 0.005 0.001 0.003 0.003 0.014 ]\n",
        "101 - Predicted: 1 Actual: 1 [ 0.382 0.556 0.012 0.001 0.009 0.007 0.033 ]\n",
        "102 - Predicted: 1 Actual: 2 [ 0.260 0.403 0.178 0.014 0.014 0.097 0.034 ]\n",
        "103 - Predicted: 1 Actual: 0 [ 0.434 0.505 0.008 0.000 0.011 0.005 0.037 ]\n",
        "104 - Predicted: 0 Actual: 1 [ 0.468 0.465 0.016 0.000 0.014 0.011 0.026 ]\n",
        "105 - Predicted: 1 Actual: 0 [ 0.466 0.470 0.015 0.001 0.007 0.007 0.034 ]\n",
        "106 - Predicted: 0 Actual: 0 [ 0.453 0.408 0.037 0.001 0.017 0.023 0.061 ]\n",
        "107 - Predicted: 1 Actual: 1 [ 0.277 0.561 0.068 0.003 0.028 0.044 0.020 ]\n",
        "108 - Predicted: 1 Actual: 1 [ 0.286 0.516 0.080 0.003 0.037 0.047 0.030 ]\n",
        "109 - Predicted: 0 Actual: 0 [ 0.536 0.387 0.023 0.002 0.008 0.009 0.035 ]\n",
        "110"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 0 Actual: 1 [ 0.598 0.336 0.013 0.001 0.007 0.008 0.036 ]\n",
        "111 - Predicted: 1 Actual: 1 [ 0.462 0.496 0.008 0.001 0.005 0.004 0.024 ]\n",
        "112 - Predicted: 0 Actual: 0 [ 0.467 0.389 0.003 0.000 0.004 0.003 0.134 ]\n",
        "113 - Predicted: 1 Actual: 1 [ 0.291 0.640 0.004 0.000 0.002 0.003 0.059 ]\n",
        "114 - Predicted: 0 Actual: 0 [ 0.544 0.361 0.015 0.001 0.008 0.008 0.064 ]\n",
        "115 - Predicted: 0 Actual: 0 [ 0.488 0.432 0.020 0.001 0.010 0.012 0.037 ]\n",
        "116 - Predicted: 1 Actual: 0 [ 0.326 0.516 0.070 0.005 0.029 0.033 0.020 ]\n",
        "117 - Predicted: 1 Actual: 1 [ 0.343 0.619 0.007 0.001 0.007 0.003 0.020 ]\n",
        "118 - Predicted: 1 Actual: 1 [ 0.412 0.517 0.017 0.001 0.012 0.009 0.032 ]\n",
        "119 - Predicted: 1 Actual: 2 [ 0.189 0.500 0.199 0.010 0.023 0.068 0.012 ]\n",
        "120"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: 1 [ 0.179 0.768 0.018 0.001 0.013 0.012 0.009 ]\n",
        "121 - Predicted: 2 Actual: 2 [ 0.099 0.277 0.405 0.036 0.014 0.160 0.009 ]\n",
        "122 - Predicted: 1 Actual: 1 [ 0.366 0.544 0.025 0.001 0.019 0.009 0.035 ]\n",
        "123 - Predicted: 1 Actual: 0 [ 0.280 0.597 0.053 0.003 0.029 0.025 0.014 ]\n",
        "124 - Predicted: 0 Actual: 1 [ 0.490 0.403 0.009 0.000 0.004 0.006 0.087 ]\n",
        "125 - Predicted: 1 Actual: 0 [ 0.350 0.454 0.103 0.009 0.018 0.035 0.031 ]\n",
        "126 - Predicted: 1 Actual: 1 [ 0.369 0.546 0.029 0.004 0.017 0.020 0.015 ]\n",
        "127 - Predicted: 1 Actual: 1 [ 0.443 0.521 0.010 0.001 0.005 0.005 0.015 ]\n",
        "128 - Predicted: 0 Actual: 0 [ 0.442 0.435 0.039 0.006 0.022 0.028 0.028 ]\n",
        "129 - Predicted: 1 Actual: 0 [ 0.462 0.474 0.017 0.003 0.013 0.015 0.016 ]\n",
        "130"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: 2 [ 0.261 0.591 0.050 0.001 0.020 0.048 0.030 ]\n",
        "131 - Predicted: 0 Actual: 1 [ 0.527 0.439 0.003 0.000 0.004 0.001 0.026 ]\n",
        "132 - Predicted: 1 Actual: 1 [ 0.367 0.540 0.025 0.000 0.020 0.016 0.033 ]\n",
        "133 - Predicted: 1 Actual: 0 [ 0.409 0.517 0.027 0.001 0.008 0.014 0.023 ]\n",
        "134 - Predicted: 1 Actual: 1 [ 0.374 0.506 0.036 0.006 0.027 0.025 0.026 ]\n",
        "135 - Predicted: 1 Actual: 1 [ 0.296 0.540 0.065 0.007 0.029 0.044 0.019 ]\n",
        "136 - Predicted: 0 Actual: 0 [ 0.482 0.475 0.003 0.000 0.005 0.003 0.033 ]\n",
        "137 - Predicted: 1 Actual: 1 [ 0.327 0.566 0.031 0.001 0.022 0.022 0.031 ]\n",
        "138 - Predicted: 1 Actual: 0 [ 0.356 0.555 0.025 0.001 0.020 0.011 0.034 ]\n",
        "139 - Predicted: 1 Actual: 0 [ 0.183 0.796 0.003 0.000 0.001 0.002 0.015 ]\n",
        "140"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 0 Actual: 0 [ 0.470 0.354 0.022 0.001 0.014 0.015 0.124 ]\n",
        "141 - Predicted: 1 Actual: 1 [ 0.349 0.598 0.008 0.000 0.005 0.005 0.034 ]\n",
        "142 - Predicted: 0 Actual: 0 [ 0.644 0.279 0.022 0.003 0.009 0.011 0.033 ]\n",
        "143 - Predicted: 1 Actual: 2 [ 0.136 0.361 0.273 0.046 0.031 0.139 0.015 ]\n",
        "144 - Predicted: 0 Actual: 1 [ 0.457 0.440 0.024 0.001 0.026 0.015 0.037 ]\n",
        "145 - Predicted: 1 Actual: 1 [ 0.363 0.558 0.016 0.001 0.015 0.012 0.036 ]\n",
        "146 - Predicted: 1 Actual: 1 [ 0.388 0.481 0.030 0.001 0.035 0.037 0.027 ]\n",
        "147 - Predicted: 0 Actual: 0 [ 0.545 0.373 0.015 0.001 0.013 0.007 0.047 ]\n",
        "148 - Predicted: 1 Actual: 0 [ 0.375 0.486 0.045 0.002 0.028 0.026 0.038 ]\n",
        "149 - Predicted: 1 Actual: 1 [ 0.381 0.580 0.010 0.000 0.004 0.005 0.019 ]\n",
        "150"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 0 Actual: 0 [ 0.557 0.330 0.011 0.001 0.007 0.007 0.087 ]\n",
        "151 - Predicted: 1 Actual: 2 [ 0.183 0.548 0.117 0.005 0.062 0.069 0.017 ]\n",
        "152 - Predicted: 1 Actual: 1 [ 0.208 0.770 0.002 0.000 0.002 0.002 0.016 ]\n",
        "153 - Predicted: 1 Actual: 1 [ 0.393 0.540 0.013 0.001 0.014 0.007 0.032 ]\n",
        "154 - Predicted: 0 Actual: 0 [ 0.481 0.447 0.009 0.002 0.010 0.009 0.043 ]\n",
        "155 - Predicted: 1 Actual: 1 [ 0.278 0.518 0.087 0.003 0.028 0.069 0.017 ]\n",
        "156 - Predicted: 1 Actual: 0 [ 0.344 0.446 0.092 0.011 0.023 0.054 0.029 ]\n",
        "157 - Predicted: 1 Actual: 1 [ 0.213 0.763 0.003 0.001 0.005 0.002 0.014 ]\n",
        "158 - Predicted: 0 Actual: 0 [ 0.554 0.400 0.012 0.001 0.005 0.008 0.020 ]\n",
        "159 - Predicted: 1 Actual: 1 [ 0.404 0.478 0.026 0.001 0.023 0.018 0.049 ]\n",
        "160"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: 0 [ 0.429 0.453 0.029 0.004 0.017 0.017 0.051 ]\n",
        "161 - Predicted: 1 Actual: 1 [ 0.478 0.482 0.005 0.001 0.010 0.004 0.020 ]\n",
        "162 - Predicted: 1 Actual: 0 [ 0.395 0.522 0.002 0.000 0.001 0.001 0.078 ]\n",
        "163 - Predicted: 1 Actual: 0 [ 0.361 0.538 0.020 0.004 0.048 0.013 0.017 ]\n",
        "164 - Predicted: 1 Actual: 1 [ 0.310 0.575 0.039 0.004 0.040 0.026 0.006 ]\n",
        "165 - Predicted: 1 Actual: 1 [ 0.424 0.471 0.036 0.001 0.012 0.014 0.041 ]\n",
        "166 - Predicted: 1 Actual: 1 [ 0.180 0.416 0.250 0.012 0.022 0.108 0.012 ]\n",
        "167 - Predicted: 1 Actual: 1 [ 0.229 0.748 0.002 0.000 0.004 0.001 0.015 ]\n",
        "168 - Predicted: 0 Actual: 0 [ 0.510 0.413 0.022 0.001 0.009 0.009 0.037 ]\n",
        "169 - Predicted: 2 Actual: 2 [ 0.107 0.202 0.459 0.031 0.031 0.146 0.024 ]\n",
        "170"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: 2 [ 0.122 0.452 0.273 0.015 0.026 0.101 0.011 ]\n",
        "171 - Predicted: 0 Actual: 0 [ 0.561 0.350 0.010 0.000 0.009 0.006 0.064 ]\n",
        "172 - Predicted: 1 Actual: 0 [ 0.401 0.425 0.074 0.005 0.017 0.038 0.040 ]\n",
        "173 - Predicted: 1 Actual: 1 [ 0.272 0.585 0.035 0.004 0.049 0.032 0.022 ]\n",
        "174 - Predicted: 0 Actual: 0 [ 0.559 0.368 0.021 0.002 0.006 0.013 0.031 ]\n",
        "175 - Predicted: 1 Actual: 1 [ 0.433 0.455 0.025 0.001 0.030 0.017 0.038 ]\n",
        "176 - Predicted: 0 Actual: 0 [ 0.453 0.407 0.045 0.003 0.018 0.020 0.055 ]\n",
        "177 - Predicted: 1 Actual: 1 [ 0.250 0.476 0.127 0.013 0.039 0.081 0.013 ]\n",
        "178 - Predicted: 1 Actual: 1 [ 0.242 0.507 0.146 0.011 0.029 0.044 0.020 ]\n",
        "179 - Predicted: 1 Actual: 1 [ 0.434 0.510 0.005 0.000 0.004 0.003 0.043 ]\n",
        "180"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: 2 [ 0.264 0.582 0.074 0.002 0.025 0.027 0.027 ]\n",
        "181 - Predicted: 1 Actual: 0 [ 0.443 0.501 0.003 0.000 0.007 0.003 0.042 ]\n",
        "182 - Predicted: 1 Actual: 1 [ 0.201 0.754 0.006 0.000 0.005 0.003 0.031 ]\n",
        "183 - Predicted: 1 Actual: 1 [ 0.229 0.489 0.105 0.014 0.031 0.111 0.021 ]\n",
        "184 - Predicted: 0 Actual: 0 [ 0.580 0.362 0.010 0.000 0.007 0.004 0.037 ]\n",
        "185 - Predicted: 0 Actual: 0 [ 0.532 0.371 0.019 0.001 0.012 0.009 0.056 ]\n",
        "186 - Predicted: 1 Actual: 0 [ 0.423 0.497 0.002 0.000 0.002 0.001 0.075 ]\n",
        "187 - Predicted: 1 Actual: 1 [ 0.287 0.490 0.107 0.012 0.026 0.063 0.015 ]\n",
        "188 - Predicted: 0 Actual: 1 [ 0.457 0.433 0.029 0.001 0.022 0.021 0.037 ]\n",
        "189 - Predicted: 1 Actual: 1 [ 0.380 0.546 0.014 0.001 0.015 0.011 0.034 ]\n",
        "190"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 0 Actual: 0 [ 0.504 0.439 0.016 0.001 0.009 0.007 0.023 ]\n",
        "191 - Predicted: 0 Actual: 1 [ 0.583 0.334 0.013 0.001 0.006 0.007 0.056 ]\n",
        "192 - Predicted: 0 Actual: 0 [ 0.469 0.461 0.018 0.001 0.016 0.014 0.022 ]\n",
        "193 - Predicted: 1 Actual: 1 [ 0.298 0.562 0.049 0.001 0.046 0.024 0.020 ]\n",
        "194 - Predicted: 1 Actual: 1 [ 0.373 0.528 0.026 0.000 0.014 0.028 0.031 ]\n",
        "195 - Predicted: 0 Actual: 0 [ 0.492 0.399 0.006 0.000 0.004 0.004 0.094 ]\n",
        "196 - Predicted: 1 Actual: 1 [ 0.251 0.643 0.037 0.004 0.032 0.018 0.016 ]\n",
        "197 - Predicted: 1 Actual: 1 [ 0.388 0.521 0.030 0.004 0.019 0.015 0.024 ]\n",
        "198 - Predicted: 1 Actual: 0 [ 0.401 0.502 0.029 0.002 0.027 0.018 0.020 ]\n",
        "199 - Predicted: 2 Actual: 2 [ 0.091 0.223 0.384 0.050 0.014 0.228 0.012 ]\n",
        "200"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " - Predicted: 1 Actual: 1 [ 0.292 0.581 0.048 0.006 0.041 0.021 0.012 ]\n",
        "201 - Predicted: 1 Actual: 1 [ 0.256 0.569 0.071 0.002 0.025 0.039 0.039 ]\n",
        "202 - Predicted: 1 Actual: 0 [ 0.443 0.480 0.015 0.002 0.027 0.013 0.020 ]\n",
        "203 - Predicted: 0 Actual: 0 [ 0.560 0.332 0.012 0.001 0.009 0.013 0.073 ]\n",
        "204 - Predicted: 1 Actual: 1 [ 0.425 0.528 0.015 0.003 0.007 0.007 0.016 ]\n",
        "205 - Predicted: 1 Actual: 2 [ 0.197 0.430 0.207 0.016 0.067 0.072 0.010 ]\n",
        "206 - Predicted: 0 Actual: 1 [ 0.501 0.400 0.027 0.002 0.016 0.015 0.039 ]\n",
        "207 - Predicted: 1 Actual: 1 [ 0.436 0.472 0.024 0.002 0.021 0.013 0.032 ]\n",
        "208 - Predicted: 0 Actual: 0 [ 0.518 0.363 0.018 0.000 0.024 0.022 0.054 ]\n",
        "209 - Predicted: 0 Actual: 0 [ 0.530 0.397 0.006 0.000 0.005 0.004 0.058 ]\n",
        "210"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.Series(hits).cumsum().plot() # Predictions over time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "<matplotlib.axes._subplots.AxesSubplot at 0x7f312436e128>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEACAYAAABS29YJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nir2ISAqo2IuIpMD/AwNjFP5WC3vYAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f31243f8f60>"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sum(hits)/len(hits) # Overall accuracy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "0.71799999999999997"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"calc_discount\", calc_discount.cache_info())\n",
      "print(\"_expected_discount_term1\", _expected_discount_term1.cache_info())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "calc_discount CacheInfo(hits=0, misses=0, maxsize=100000, currsize=0)\n",
        "_expected_discount_term1 CacheInfo(hits=0, misses=0, maxsize=100000, currsize=0)\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i, tree in enumerate(mf.trees):\n",
      "    print(\"Tree %d posterior cache hits: %d\" % (i, tree._scorer.cache_hits))\n",
      "    print(\"Tree %d posterior cache misses: %d\" % (i, tree._scorer.cache_misses))\n",
      "    print(\"Tree %d posterior cache evictions: %d\" % (i, tree._scorer.cache_evictions))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "calc_discount CacheInfo(hits=0, misses=0, maxsize=100000, currsize=0)\n",
        "_expected_discount_term1 CacheInfo(hits=0, misses=0, maxsize=100000, currsize=0)\n"
       ]
      },
      {
       "ename": "AttributeError",
       "evalue": "'ParallelMondrianForest' object has no attribute 'trees'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-9-69e02267cdd0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"calc_discount\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcalc_discount\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_expected_discount_term1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_expected_discount_term1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtree\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Tree %d posterior cache hits: %d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scorer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_hits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Tree %d posterior cache misses: %d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scorer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_misses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mAttributeError\u001b[0m: 'ParallelMondrianForest' object has no attribute 'trees'"
       ]
      }
     ],
     "prompt_number": 9
    }
   ],
   "metadata": {}
  }
 ]
}